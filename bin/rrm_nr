#!/bin/sh
# 802.11k NR distributor helper

NAME=rrm_nr
UPDATE_INTERVAL=60
JITTER_MAX=10
UMDNS_REFRESH_INTERVAL=30
UMDNS_SETTLE_DELAY=0

num_re='^[0-9][0-9]*$'
[ -n "$RRM_NR_UPDATE_INTERVAL" ] && echo "$RRM_NR_UPDATE_INTERVAL" | grep -qE "$num_re" && UPDATE_INTERVAL=$RRM_NR_UPDATE_INTERVAL
[ -n "$RRM_NR_JITTER_MAX" ] && echo "$RRM_NR_JITTER_MAX" | grep -qE "$num_re" && JITTER_MAX=$RRM_NR_JITTER_MAX
[ -n "$RRM_NR_UMDNS_REFRESH_INTERVAL" ] && echo "$RRM_NR_UMDNS_REFRESH_INTERVAL" | grep -qE "$num_re" && UMDNS_REFRESH_INTERVAL=$RRM_NR_UMDNS_REFRESH_INTERVAL
[ -n "$RRM_NR_UMDNS_SETTLE_DELAY" ] && echo "$RRM_NR_UMDNS_SETTLE_DELAY" | grep -qE "$num_re" && UMDNS_SETTLE_DELAY=$RRM_NR_UMDNS_SETTLE_DELAY
DEBUG=0; [ "$RRM_NR_DEBUG" = 1 ] && DEBUG=1

# Bounded cycles (test harness)
MAX_CYCLES=0
if [ -n "$RRM_NR_MAX_CYCLES" ] && echo "$RRM_NR_MAX_CYCLES" | grep -qE '^[0-9]+'; then
	MAX_CYCLES="$RRM_NR_MAX_CYCLES"
fi

# Sanity depending on mode (allow small in test mode)
if [ "$MAX_CYCLES" -gt 0 ]; then
	[ "$UPDATE_INTERVAL" -lt 1 ] 2>/dev/null && UPDATE_INTERVAL=1
	[ "$UMDNS_REFRESH_INTERVAL" -lt 1 ] 2>/dev/null && UMDNS_REFRESH_INTERVAL=1
else
	[ "$UPDATE_INTERVAL" -lt 5 ] 2>/dev/null && UPDATE_INTERVAL=5
	[ "$UMDNS_REFRESH_INTERVAL" -lt 5 ] 2>/dev/null && UMDNS_REFRESH_INTERVAL=5
fi
[ "$JITTER_MAX" -gt $((UPDATE_INTERVAL / 2)) ] 2>/dev/null && JITTER_MAX=$((UPDATE_INTERVAL / 2))
[ "$UMDNS_SETTLE_DELAY" -lt 0 ] 2>/dev/null && UMDNS_SETTLE_DELAY=0

hm_create() {
	umask 077
	d=$(mktemp -d 2>/dev/null)
	[ -z "$d" ] && d=/tmp/rrm_nr.$$ && mkdir -p "$d" 2>/dev/null
	echo "$d"
}
hashmap=$(hm_create)
state_dir=/tmp/rrm_nr_state; [ -d "$state_dir" ] || mkdir -p "$state_dir" 2>/dev/null

debug() {
	[ "$DEBUG" = 1 ] || return
	command -v logger >/dev/null 2>&1 && logger -t "$NAME" -p daemon.debug "$*"
	[ -n "$LOG_FILE" ] && printf '%s %s\n' "$(date +%s 2>/dev/null)" "$NAME:DEBUG:$*" >> "$LOG_FILE" 2>/dev/null
}

cleanup() {
	rc=$?
	rm -rf "$hashmap"
	command -v logger >/dev/null 2>&1 && logger -t "$NAME" -p daemon.info "Removed hash map directory: $hashmap"
	exit $rc
}
trap cleanup EXIT INT TERM QUIT

hm_put(){ printf '%s\n' "$3" > "$1/$2"; }
hm_get(){ [ -f "$1/$2" ] && cat "$1/$2"; }
rand_jitter(){ [ "$JITTER_MAX" -gt 0 ] 2>/dev/null || { echo 0; return; }; v=$(dd if=/dev/urandom bs=2 count=1 2>/dev/null | od -An -tu2 | tr -d ' '); [ -z "$v" ] && echo 0 || echo $(( v % (JITTER_MAX + 1) )); }

first_run=1
last_umdns_update=0
skip_ifaces="$RRM_NR_SKIP_IFACES"
sleep_pid=""
runtime_state_file=/tmp/rrm_nr_runtime
last_reload_time=$(date +%s 2>/dev/null)
force_update_test="$RRM_NR_TEST_FORCE_UPDATE"
CYCLE_COUNT=0
last_update_time=0
cache_hits=0
cache_misses=0
nr_sets_sent=0
nr_sets_suppressed=0
remote_entries_merged=0
baseline_sent_hashes="" # space-delimited list of ssid_hash values already baseline-pushed
baseline_ssids=0 # count of distinct SSIDs baseline-delivered this process
remote_unique_cycle=0 # unique remote TXT entries seen in the most recent cycle
remote_unique_total=0 # cumulative distinct remote TXT entries since start
remote_seen_file="$state_dir/remote_seen"
[ -n "$neighbor_counts" ] || neighbor_counts="" # per-interface neighbor counts (post self-filter)
[ -n "$nr_set_failures" ] || nr_set_failures=0 # failures from rrm_nr_set ubus call
[ -f "$remote_seen_file" ] || { umask 077; : > "$remote_seen_file"; }
debug "startup: interval=$UPDATE_INTERVAL jitter=$JITTER_MAX umdns=$UMDNS_REFRESH_INTERVAL max_cycles=$MAX_CYCLES"

# Source shared helpers if available
[ -f /lib/rrm_nr_common.sh ] && . /lib/rrm_nr_common.sh 2>/dev/null || true

# Fallback minimal implementation for rrm_get_own_quick if library not present.
# Returns JSON from ubus or non-zero on failure. Includes light retry on rc=4.
if ! type rrm_get_own_quick >/dev/null 2>&1; then
rrm_get_own_quick() {
	_ifc="$1"; [ -z "$_ifc" ] && return 1
	_attempt=0
	while [ $_attempt -lt 4 ]; do
		out=$(ubus call "hostapd.$_ifc" rrm_nr_get_own 2>/dev/null)
		rc=$?
		[ $rc -eq 0 ] && { [ -n "$out" ] && printf '%s' "$out"; return 0; }
		# rc=4 often means initial transient (object not ready) – retry quickly
		[ $rc -ne 4 ] && return $rc
		_attempt=$((_attempt+1))
		sleep 1
	done
	return 1
}
debug "Using internal fallback rrm_get_own_quick (library missing)"
fi

# Apply normalization to initial env-provided skip list
if [ -n "$skip_ifaces" ]; then
	skip_ifaces=$(normalize_iflist "$skip_ifaces")
fi

write_state(){
	umask 077
	{
		echo "update_interval=$UPDATE_INTERVAL"
		echo "jitter_max=$JITTER_MAX"
		echo "umdns_refresh_interval=$UMDNS_REFRESH_INTERVAL"
		echo "umdns_settle_delay=$UMDNS_SETTLE_DELAY"
		echo "debug=$DEBUG"
		echo "skip_ifaces=$skip_ifaces"
		echo "last_reload=$last_reload_time"
		echo "cycle=$CYCLE_COUNT"
		echo "last_update_time=$last_update_time"
	} > "$runtime_state_file.tmp" 2>/dev/null && mv "$runtime_state_file.tmp" "$runtime_state_file" 2>/dev/null
}

metrics_file=/tmp/rrm_nr_metrics
write_metrics(){
	umask 077
	# Derive suppression ratio (percentage of potential per-iface updates suppressed as no-change)
	total_updates=$((nr_sets_sent + nr_sets_suppressed))
	if [ "$total_updates" -gt 0 ]; then
		suppression_ratio_pct=$((nr_sets_suppressed * 100 / total_updates))
	else
		suppression_ratio_pct=0
	fi
	{
		echo "cycle=$CYCLE_COUNT"
		echo "cache_hits=$cache_hits"
		echo "cache_misses=$cache_misses"
		echo "nr_sets_sent=$nr_sets_sent"
		echo "nr_sets_suppressed=$nr_sets_suppressed"
		echo "remote_entries_merged=$remote_entries_merged"
		echo "remote_unique_cycle=$remote_unique_cycle"
		echo "remote_unique_total=$remote_unique_total"
		echo "last_update_time=$last_update_time"
		echo "baseline_ssids=$baseline_ssids"
		echo "suppression_ratio_pct=$suppression_ratio_pct"
		echo "nr_set_failures=$nr_set_failures"
		# Per-interface neighbor counts (post self-filter sizing)
		for nc in $neighbor_counts; do
			ifc=${nc%%:*}; cnt=${nc#*:}; [ -n "$ifc" ] && echo "neighbor_count_${ifc}=$cnt"
		done
	} > "$metrics_file.tmp" 2>/dev/null && mv "$metrics_file.tmp" "$metrics_file" 2>/dev/null
}

# shellcheck disable=SC2329
reload_config(){
	v=$(uci -q get rrm_nr.global.update_interval 2>/dev/null); echo "$v" | grep -qE '^[0-9]+' && UPDATE_INTERVAL=$v
	v=$(uci -q get rrm_nr.global.jitter_max 2>/dev/null); echo "$v" | grep -qE '^[0-9]+' && JITTER_MAX=$v
	v=$(uci -q get rrm_nr.global.umdns_refresh_interval 2>/dev/null); echo "$v" | grep -qE '^[0-9]+' && UMDNS_REFRESH_INTERVAL=$v
	v=$(uci -q get rrm_nr.global.umdns_settle_delay 2>/dev/null); echo "$v" | grep -qE '^[0-9]+' && UMDNS_SETTLE_DELAY=$v
	dbg=$(uci -q get rrm_nr.global.debug 2>/dev/null); [ "$dbg" = 1 ] && DEBUG=1 || DEBUG=0
	# skip_ifaces (space separated)
	lst=$(uci -q get rrm_nr.global.skip_ifaces 2>/dev/null)
	[ -n "$lst" ] || lst=$(uci -q show rrm_nr.global 2>/dev/null | sed -n "s/^rrm_nr.global.skip_iface='\(.*\)'$/\1/p" | tr '\n' ' ')
	# Normalize (reuse function) to allow commas/tabs & de-dupe
	skip_ifaces=$(normalize_iflist "$lst")
	:
	if [ "$MAX_CYCLES" -gt 0 ]; then
		[ "$UPDATE_INTERVAL" -lt 1 ] 2>/dev/null && UPDATE_INTERVAL=1
		[ "$UMDNS_REFRESH_INTERVAL" -lt 1 ] 2>/dev/null && UMDNS_REFRESH_INTERVAL=1
	else
		[ "$UPDATE_INTERVAL" -lt 5 ] 2>/dev/null && UPDATE_INTERVAL=5
		[ "$UMDNS_REFRESH_INTERVAL" -lt 5 ] 2>/dev/null && UMDNS_REFRESH_INTERVAL=5
	fi
	[ "$JITTER_MAX" -gt $((UPDATE_INTERVAL / 2)) ] 2>/dev/null && JITTER_MAX=$((UPDATE_INTERVAL / 2))
	[ "$UMDNS_SETTLE_DELAY" -lt 0 ] 2>/dev/null && UMDNS_SETTLE_DELAY=0
	last_reload_time=$(date +%s 2>/dev/null)
	write_state
}

# shellcheck disable=SC2329
handle_hup(){
	old="$UPDATE_INTERVAL/$JITTER_MAX/$UMDNS_REFRESH_INTERVAL"
	reload_config
	new="$UPDATE_INTERVAL/$JITTER_MAX/$UMDNS_REFRESH_INTERVAL"
	command -v logger >/dev/null 2>&1 && logger -t "$NAME" -p daemon.info "Reload (SIGHUP): $old -> $new"
	# If interval shortened, trigger immediate update cycle
	if [ "$last_update_time" -gt 0 ] && [ "$UPDATE_INTERVAL" -lt $(( ( $(date +%s 2>/dev/null) - last_update_time ) + 1 )) ]; then
		do_updates; CYCLE_COUNT=$((CYCLE_COUNT+1)); write_state
	fi
	[ -n "$sleep_pid" ] && [ -d /proc/"$sleep_pid" ] && kill -INT "$sleep_pid" 2>/dev/null || true
}
trap handle_hup HUP

handle_usr1(){
	command -v logger >/dev/null 2>&1 && logger -t "$NAME" -p daemon.info "Manual refresh (SIGUSR1)"
	do_updates; CYCLE_COUNT=$((CYCLE_COUNT+1)); write_state; write_metrics
}
handle_usr2(){
	ts=$(date +%s 2>/dev/null)
	[ -f "$metrics_file" ] && cp "$metrics_file" "${metrics_file}.${ts}" 2>/dev/null || true
	cache_hits=0; cache_misses=0; nr_sets_sent=0; nr_sets_suppressed=0; remote_entries_merged=0
	remote_unique_cycle=0; remote_unique_total=0
	neighbor_counts=""
	# Reset seen file (remote uniqueness cumulative set)
	[ -n "$remote_seen_file" ] && : > "$remote_seen_file" 2>/dev/null || true
	command -v logger >/dev/null 2>&1 && logger -t "$NAME" -p daemon.info "Metrics reset (SIGUSR2)"
	write_metrics
}
trap handle_usr1 USR1
trap handle_usr2 USR2

build_mapping(){
	hostapd_members=$(ubus list hostapd.* 2>/dev/null | sed 's/^hostapd.//')
	[ -z "$hostapd_members" ] && return
	for i in $hostapd_members; do
		ssid=$(iwinfo "$i" info 2>/dev/null | sed -n 's/^ESSID: "\(.*\)"$/\1/p')
		[ -z "$ssid" ] && ssid=$(ubus call hostapd.$i bss | jsonfilter -e '@.ssid' 2>/dev/null)
		if [ -z "$ssid" ]; then
			own_json=$(rrm_get_own_quick "$i" 2>/dev/null)
			[ -n "$own_json" ] && ssid=$(echo "$own_json" | jsonfilter -e '$.value[1]' 2>/dev/null)
		fi
		[ -n "$ssid" ] && hm_put "$hashmap" "$i" "$ssid" || debug "build_mapping: iface=$i ssid=(missing)"
	done
	debug "build_mapping: $(for i in $hostapd_members; do s=$(hm_get "$hashmap" "$i"); [ -n "$s" ] && printf '%s=%s ' "$i" "$s"; done)"
}

do_updates(){
	# First run: build SSID mapping
	if [ "$first_run" -eq 1 ]; then
		build_mapping; first_run=0
	fi
	now=$(date +%s 2>/dev/null); [ -z "$now" ] && now=0
	if [ $((now - last_umdns_update)) -ge "$UMDNS_REFRESH_INTERVAL" ]; then
		ubus call umdns update >/dev/null 2>&1; last_umdns_update=$now; debug "Triggered umdns update"; [ "$UMDNS_SETTLE_DELAY" -gt 0 ] && sleep "$UMDNS_SETTLE_DELAY"
	fi
	[ -z "$hostapd_members" ] && hostapd_members=$(ubus list hostapd.* 2>/dev/null | sed 's/^hostapd.//')
	[ -z "$hostapd_members" ] && return

	# Pass 1: collect per-interface own NR (single ubus call per iface) & build SSID membership map file
	valdir=$(mktemp -d 2>/dev/null) || valdir=/tmp/rrm_nr_vals.$$ && mkdir -p "$valdir"
	ssid_map="$valdir/ssid_map"
	: > "$ssid_map"
	for ifc in $hostapd_members; do
		ssid=$(hm_get "$hashmap" "$ifc")
		[ -z "$ssid" ] && continue
		v_json=$(rrm_get_own_quick "$ifc") || { debug "$ifc: rrm_nr_get_own not ready (skipping this cycle)"; continue; }
		v_bssid=$(echo "$v_json" | jsonfilter -e '$.value[0]' 2>/dev/null)
		v_ssid=$(echo  "$v_json" | jsonfilter -e '$.value[1]' 2>/dev/null)
		v_hex=$(echo   "$v_json" | jsonfilter -e '$.value[2]' 2>/dev/null)
		if [ -n "$v_bssid" ] && [ -n "$v_ssid" ] && [ -n "$v_hex" ]; then
			v="[\"$v_bssid\",\"$v_ssid\",\"$v_hex\"]"
			printf '%s' "$v" > "$valdir/$ifc"
			debug "$ifc: own_nr=$v"
		else
			debug "$ifc: incomplete own_nr (bssid='$v_bssid' ssid='$v_ssid' hex_len=${#v_hex})"
		fi
		echo "$ssid|$ifc" >> "$ssid_map"
	done

	# Gather remote (mDNS) entries once
	remote_tmp=$(mktemp 2>/dev/null) || remote_tmp=/tmp/rrm_nr_remote.$$
	ubus call umdns browse '{ "service":"_rrm_nr._udp", "array": true }' 2>/dev/null | \
		jsonfilter -e '@["_rrm_nr._udp"][*].txt[*]' 2>/dev/null | sed -n 's/^SSID[0-9]*=//p' | sed 's/^ *//;s/ *$//' > "$remote_tmp" 2>/dev/null || true
	# Count remote entries merged this cycle (additive cumulative counter)
	if [ -s "$remote_tmp" ]; then
		cnt=$(wc -l < "$remote_tmp" 2>/dev/null); [ -n "$cnt" ] && remote_entries_merged=$((remote_entries_merged + cnt))
		# Derive unique remote entries for this cycle & update cumulative set (normalized)
		unique_remote=$(sort -u "$remote_tmp" | sed '/^$/d')
		remote_unique_cycle=$(printf '%s\n' "$unique_remote" | wc -l 2>/dev/null)
		if [ -n "$unique_remote" ]; then
			while IFS= read -r rline; do
				[ -z "$rline" ] && continue
				norm=$(printf '%s' "$rline" | sed 's/  */ /g')
				grep -Fqx -- "$norm" "$remote_seen_file" 2>/dev/null || echo "$norm" >> "$remote_seen_file"
			done <<EOF
$unique_remote
EOF
			remote_unique_total=$(wc -l < "$remote_seen_file" 2>/dev/null)
		else
			remote_unique_cycle=0
		fi
		debug "remote_entries: $cnt unique_cycle=$remote_unique_cycle unique_total=$remote_unique_total"
	fi

	# Unique list of SSIDs
	ssid_list=$(cut -d'|' -f1 "$ssid_map" 2>/dev/null | sed '/^$/d' | sort -u)
	if [ -z "$ssid_list" ]; then
		debug "do_updates: no local SSIDs mapped (skipping cache build)"
		rm -rf "$valdir" "$remote_tmp"
		return
	fi

	# Prepare cache directory
	cache_dir="$state_dir/group_cache"; [ -d "$cache_dir" ] || mkdir -p "$cache_dir" 2>/dev/null

	for ssid in $ssid_list; do
		# Build group interface membership for this SSID
		group_ifcs=$(grep -E "^${ssid}\|" "$ssid_map" 2>/dev/null | cut -d'|' -f2)
		# Build candidate list (other ifaces in same SSID + remote entries)
		cand_tmp=$(mktemp 2>/dev/null) || cand_tmp=/tmp/rrm_nr_cand.$$
		for gi in $group_ifcs; do
			own_val=$(cat "$valdir/$gi" 2>/dev/null)
			[ -n "$own_val" ] && printf '%s\n' "$own_val" >> "$cand_tmp"
		done
		# remote entries appended
		[ -s "$remote_tmp" ] && cat "$remote_tmp" >> "$cand_tmp"
		# If only one line and it belongs to the interface itself there will be no neighbors; remove self contribution later per iface.
		[ ! -s "$cand_tmp" ] && { rm -f "$cand_tmp"; debug "ssid='$ssid': no candidates"; continue; }
		# De-dup via sort -u (still cheaper than per-iface ubus loops) – could be optimized later.
		unique=$(sort -u "$cand_tmp" | sed '/^$/d')
			echo "remote_unique_cycle=$remote_unique_cycle"
			echo "remote_unique_total=$remote_unique_total"
		rm -f "$cand_tmp"
		[ -z "$unique" ] && { debug "ssid='$ssid': unique list empty"; continue; }
		debug "ssid='$ssid': unique_lines=$(printf '%s' "$unique" | wc -l 2>/dev/null) sample_first='$(printf '%s' "$unique" | head -n1)'"
		debug "ssid='$ssid': candidates_count=$(printf '%s\n' "$unique" | wc -l 2>/dev/null)"
		# Canonicalize, de-duplicate (by SSID+BSSID) and produce stable ordering (SSID then BSSID)
		canon_tmp="$valdir/canon.$$"; : > "$canon_tmp"
		printf '%s\n' "$unique" | while IFS= read -r line; do
			l=$(printf '%s' "$line" | sed 's/^ *//;s/ *$//')
			[ -z "$l" ] && continue
			printf '%s' "$l" | grep -q '^\[' || continue
			core=$(printf '%s' "$l" | sed -E 's/^\[ *//; s/ *\]$//')
			bssid=$(printf '%s' "$core" | awk -F',' '{print $1}' | sed 's/[" ]//g')
			ssid_part=$(printf '%s' "$core" | awk -F',' '{print $2}')
			hex=$(printf '%s' "$core" | awk -F',' '{print $3}' | sed 's/[" ]//g')
			ssid_part=$(printf '%s' "$ssid_part" | sed 's/^ *//;s/ *$//')
			ssid_clean=$(printf '%s' "$ssid_part" | sed 's/^"//;s/"$//')
			[ -n "$bssid" ] && [ -n "$ssid_clean" ] && [ -n "$hex" ] && printf '["%s","%s","%s"]\n' "$bssid" "$ssid_clean" "$hex" >> "$canon_tmp"
		done
		canon_sorted_tmp="$valdir/canon_sorted.$$"; : > "$canon_sorted_tmp"
		if [ -s "$canon_tmp" ]; then
			awk 'BEGIN{FS="\""; OFS=""} /^\[/ { bssid=$2; ssid=$4; key=ssid"|"bssid; if(!seen[key]++){ printf "%s\t%s\t%s\n", ssid,bssid,$0 } }' "$canon_tmp" | \
				sort -t '\t' -k1,1 -k2,2 | cut -f3- > "$canon_sorted_tmp"
		fi
		canon=$(cat "$canon_sorted_tmp" 2>/dev/null)
		rm -f "$canon_tmp" "$canon_sorted_tmp" 2>/dev/null || true
		[ -z "$canon" ] && { debug "group_build: ssid='$ssid' canonicalization produced empty set"; list="[]"; compact=""; }
		if [ -z "$list" ] || [ -z "$canon" ]; then
			compact=$(printf '%s\n' "$canon" | awk 'NF{ if(n)printf(","); printf("%s",$0); n=1 }')
			[ -n "$compact" ] && list="[$compact]" || list="[]"
		fi
		debug "group_build: ssid='$ssid' canon_count=$(printf '%s\n' "$canon" | sed '/^$/d' | wc -l 2>/dev/null) compact_len=${#compact} list_sample='$(printf '%.120s' "$list")'"
		# Group cache key
		ssid_hash=$(printf '%s' "$ssid" | md5sum 2>/dev/null | awk '{print $1}')
		[ -z "$ssid_hash" ] && ssid_hash=$(printf '%s' "$ssid" | wc -c)
		cache_file="$cache_dir/$ssid_hash.list"
		prev_list=""
		[ -f "$cache_file" ] && prev_list=$(cat "$cache_file" 2>/dev/null)
		# Compare stripped spaces
		new_norm=$(printf '%s' "$list" | tr -d ' ')
		old_norm=$(printf '%s' "$prev_list" | tr -d ' ')
		changed=0
		# If previous list was empty array and we now have candidates (unique non-empty, list not '[]') force update
		if [ "$old_norm" = "[]" ] && [ -n "$compact" ]; then
			force_write=1
		else
			force_write=0
		fi
		if [ "$force_update_test" = 1 ] || [ "$new_norm" != "$old_norm" ] || [ "$force_write" = 1 ]; then
			changed=1; cache_misses=$((cache_misses+1))
			echo "$list" > "$cache_file" 2>/dev/null
			debug "cache_write: ssid='$ssid' file=$(basename "$cache_file") size=${#list}"
		else
			cache_hits=$((cache_hits+1))
			debug "cache_hit: ssid='$ssid'"
		fi
		# Ensure each SSID gets a baseline push exactly once after daemon start even if unchanged
		case " $baseline_sent_hashes " in
			*" $ssid_hash "*) baseline_done=1 ;;
			*) baseline_done=0 ;;
		esac
		if [ "$baseline_done" -eq 0 ] && [ "$changed" -eq 0 ]; then
			changed=1
			baseline_ssids=$((baseline_ssids+1))
			debug "force_initial_push: ssid='$ssid' (baseline deliver)"
		fi
		if [ "$changed" -eq 0 ]; then
			# count suppressed sets for each iface in group (excluding skipped)
			for gi in $group_ifcs; do case " $skip_ifaces " in *" $gi "*) continue ;; esac; nr_sets_suppressed=$((nr_sets_suppressed+1)); done
			continue
		fi
		# Apply updated list to each interface in group except those skipped
		for gi in $group_ifcs; do
			case " $skip_ifaces " in *" $gi "*) continue ;; esac
			own_val=$(cat "$valdir/$gi" 2>/dev/null)
			final_list="$list"
			if [ -n "$own_val" ]; then
				# Self-filter using canonical (ordered) set
				filtered=$(printf '%s\n' "$canon" | grep -Fv -- "$own_val" | sed '/^$/d')
				orig_count=$(printf '%s\n' "$canon" | sed '/^$/d' | wc -l 2>/dev/null)
				filt_count=0
				if [ -n "$filtered" ]; then
					filt_count=$(printf '%s\n' "$filtered" | sed '/^$/d' | wc -l 2>/dev/null)
					joined=$(printf '%s\n' "$filtered" | awk 'NF{ if(n)printf(","); printf("%s",$0); n=1 }')
					[ -n "$joined" ] && final_list="[$joined]" || final_list="[]"
				else
					final_list="[]"
				fi
				[ "$DEBUG" = 1 ] && debug "$gi: filter self (orig=$orig_count after=$filt_count)"
			fi
			resp=$(ubus call hostapd."$gi" rrm_nr_set "{ \"list\": $final_list }" 2>/dev/null)
			rc=$?
			if [ $rc -eq 0 ]; then
				debug "$gi: updated list (rc=0) list=$final_list resp=${resp:-<empty>}"
				last_update_time=$(date +%s 2>/dev/null)
				nr_sets_sent=$((nr_sets_sent+1))
				# neighbor count (post self-filter)
				neighbor_count=$(printf '%s' "$final_list" | grep -o '\["' | wc -l 2>/dev/null)
				# update neighbor_counts map (remove old entry for iface)
				new_map=""; for nc in $neighbor_counts; do case "$nc" in ${gi}:*) continue ;; esac; new_map="$new_map $nc"; done; neighbor_counts="$new_map ${gi}:$neighbor_count"
			else
				nr_set_failures=$((nr_set_failures+1))
				debug "$gi: rrm_nr_set failed rc=$rc list=$final_list resp=${resp:-<empty>}"
			fi
		done
		# Mark baseline sent for this SSID (so we don't force again)
		case " $baseline_sent_hashes " in *" $ssid_hash "*) ;; *) baseline_sent_hashes="$baseline_sent_hashes $ssid_hash" ;; esac
	 done
	rm -rf "$valdir" "$remote_tmp" 2>/dev/null || true
}

write_state; do_updates; CYCLE_COUNT=$((CYCLE_COUNT+1)); write_metrics
[ "$MAX_CYCLES" -gt 0 ] && [ "$CYCLE_COUNT" -ge "$MAX_CYCLES" ] && exit 0
while :; do
	if [ "$MAX_CYCLES" -gt 0 ] && [ "$CYCLE_COUNT" -ge "$MAX_CYCLES" ]; then exit 0; fi
	j=$(rand_jitter); sl=$((UPDATE_INTERVAL + j)); [ "$sl" -lt 1 ] && sl=1
	sleep "$sl" & sleep_pid=$!; wait "$sleep_pid" 2>/dev/null; sleep_pid=""
	do_updates; CYCLE_COUNT=$((CYCLE_COUNT+1)); write_state; write_metrics
done

exit 0